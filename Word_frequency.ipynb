{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\r\n",
      "udev            7.9G   12K  7.9G   1% /dev\r\n",
      "tmpfs           1.6G  404K  1.6G   1% /run\r\n",
      "/dev/vda1       158G   24G  128G  16% /\r\n",
      "none            4.0K     0  4.0K   0% /sys/fs/cgroup\r\n",
      "none            5.0M     0  5.0M   0% /run/lock\r\n",
      "none            7.9G     0  7.9G   0% /run/shm\r\n",
      "none            100M   20K  100M   1% /run/user\r\n",
      "/dev/vda15      105M  3.2M  102M   4% /boot/efi\r\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "pd.options.display.max_rows = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_review = pd.read_pickle('yelp_review_cleaned_0710.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>lemma_clean</th>\n",
       "      <th>sent_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0W4lkclzZThpx3V65bVgig</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>v0i_UHJMo_hPBq9bxWvW4w</td>\n",
       "      <td>5</td>\n",
       "      <td>Love the staff, love the meat, love the place....</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[love, the, staff, love, the, meat, love, the,...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[super, simple, place, but, amazing, nonethele...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>5</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[small, unassum, place, that, change, PRON, me...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>5</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[lester, s, be, locate, in, a, beautiful, neig...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>4</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[love, come, here, yes, the, place, always, ne...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s2I_Ni76bjJNK9yG60iD-Q</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>L_9BTb55X0GDtThi6GlZ6w</td>\n",
       "      <td>4</td>\n",
       "      <td>Had their chocolate almond croissant and it wa...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[have, PRON, chocolate, almond, croissant, and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8QWPlVQ6D-OExqXoaD2Z1g</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-24</td>\n",
       "      <td>0</td>\n",
       "      <td>HRPm3vEZ_F-33TYVT7Pebw</td>\n",
       "      <td>5</td>\n",
       "      <td>Cycle Pub Las Vegas was a blast! Got a groupon...</td>\n",
       "      <td>1</td>\n",
       "      <td>_4iMDXbXZ1p1ONG297YEAQ</td>\n",
       "      <td>[cycle, pub, las, vegas, be, a, blast, get, a,...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9_CGhHMz8698M9-PkVf0CQ</td>\n",
       "      <td>2</td>\n",
       "      <td>2012-05-11</td>\n",
       "      <td>0</td>\n",
       "      <td>ymAUG8DZfQcFTBSOiaNN4w</td>\n",
       "      <td>4</td>\n",
       "      <td>Who would have guess that you would be able to...</td>\n",
       "      <td>0</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>[who, would, have, guess, that, PRON, would, b...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gkCorLgPyQLsptTHalL61g</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-10-27</td>\n",
       "      <td>0</td>\n",
       "      <td>8UIishPUD92hXtScSga_gw</td>\n",
       "      <td>4</td>\n",
       "      <td>Always drove past this coffee house and wonder...</td>\n",
       "      <td>1</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>[always, drive, past, this, coffee, house, and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5r6-G9C4YLbC7Ziz57l3rQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-02-09</td>\n",
       "      <td>0</td>\n",
       "      <td>w41ZS9shepfO3uEyhXEWuQ</td>\n",
       "      <td>3</td>\n",
       "      <td>Not bad!! Love that there is a gluten-free, ve...</td>\n",
       "      <td>1</td>\n",
       "      <td>u0LXt3Uea_GidxRW1xcsfg</td>\n",
       "      <td>[not, bad, love, that, there, be, a, gluten, f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny               review_id  \\\n",
       "0  0W4lkclzZThpx3V65bVgig     0 2016-05-28      0  v0i_UHJMo_hPBq9bxWvW4w   \n",
       "1  AEx2SYEUJmTxVVB18LlCwA     0 2016-05-28      0  vkVSCC7xljjrAI4UGfnKEQ   \n",
       "2  VR6GpWIda3SfvPC-lg9H3w     0 2016-05-28      0  n6QzIUObkYshz4dz2QRJTw   \n",
       "3  CKC0-MOWMqoeWf6s-szl8g     0 2016-05-28      0  MV3CcKScW05u5LVfF6ok0g   \n",
       "4  ACFtxLv8pGrrxMm6EgjreA     0 2016-05-28      0  IXvOzsEMYtiJI0CARmj77Q   \n",
       "5  s2I_Ni76bjJNK9yG60iD-Q     0 2016-05-28      0  L_9BTb55X0GDtThi6GlZ6w   \n",
       "6  8QWPlVQ6D-OExqXoaD2Z1g     0 2014-09-24      0  HRPm3vEZ_F-33TYVT7Pebw   \n",
       "7  9_CGhHMz8698M9-PkVf0CQ     2 2012-05-11      0  ymAUG8DZfQcFTBSOiaNN4w   \n",
       "8  gkCorLgPyQLsptTHalL61g     0 2015-10-27      0  8UIishPUD92hXtScSga_gw   \n",
       "9  5r6-G9C4YLbC7Ziz57l3rQ     0 2013-02-09      0  w41ZS9shepfO3uEyhXEWuQ   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      5  Love the staff, love the meat, love the place....       0   \n",
       "1      5  Super simple place but amazing nonetheless. It...       0   \n",
       "2      5  Small unassuming place that changes their menu...       0   \n",
       "3      5  Lester's is located in a beautiful neighborhoo...       0   \n",
       "4      4  Love coming here. Yes the place always needs t...       0   \n",
       "5      4  Had their chocolate almond croissant and it wa...       0   \n",
       "6      5  Cycle Pub Las Vegas was a blast! Got a groupon...       1   \n",
       "7      4  Who would have guess that you would be able to...       0   \n",
       "8      4  Always drove past this coffee house and wonder...       1   \n",
       "9      3  Not bad!! Love that there is a gluten-free, ve...       1   \n",
       "\n",
       "                  user_id                                        lemma_clean  \\\n",
       "0  bv2nCi5Qv5vroFiqKGopiw  [love, the, staff, love, the, meat, love, the,...   \n",
       "1  bv2nCi5Qv5vroFiqKGopiw  [super, simple, place, but, amazing, nonethele...   \n",
       "2  bv2nCi5Qv5vroFiqKGopiw  [small, unassum, place, that, change, PRON, me...   \n",
       "3  bv2nCi5Qv5vroFiqKGopiw  [lester, s, be, locate, in, a, beautiful, neig...   \n",
       "4  bv2nCi5Qv5vroFiqKGopiw  [love, come, here, yes, the, place, always, ne...   \n",
       "5  bv2nCi5Qv5vroFiqKGopiw  [have, PRON, chocolate, almond, croissant, and...   \n",
       "6  _4iMDXbXZ1p1ONG297YEAQ  [cycle, pub, las, vegas, be, a, blast, get, a,...   \n",
       "7  u0LXt3Uea_GidxRW1xcsfg  [who, would, have, guess, that, PRON, would, b...   \n",
       "8  u0LXt3Uea_GidxRW1xcsfg  [always, drive, past, this, coffee, house, and...   \n",
       "9  u0LXt3Uea_GidxRW1xcsfg  [not, bad, love, that, there, be, a, gluten, f...   \n",
       "\n",
       "   sent_count  \n",
       "0           6  \n",
       "1           3  \n",
       "2           8  \n",
       "3           4  \n",
       "4           6  \n",
       "5           5  \n",
       "6           8  \n",
       "7           6  \n",
       "8           5  \n",
       "9           5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aaa = df_review['lemma'][0]\n",
    "text1 = [' '.join(aaa)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### each row in the lemma column is a list of words. Now converting it back \n",
    "### to text/str, so CountVectorizor has one row for each review\n",
    "df_review['lemmatized'] = map(lambda x: [' '.join(x)],df_review['lemma_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_review.to_pickle('yelp_review_cleaned_0710v2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 12 columns):\n",
      "business_id    100000 non-null object\n",
      "cool           100000 non-null int64\n",
      "date           100000 non-null datetime64[ns]\n",
      "funny          100000 non-null int64\n",
      "review_id      100000 non-null object\n",
      "stars          100000 non-null int64\n",
      "text           100000 non-null object\n",
      "useful         100000 non-null int64\n",
      "user_id        100000 non-null object\n",
      "lemma_clean    100000 non-null object\n",
      "sent_count     100000 non-null int64\n",
      "lemmatized     100000 non-null object\n",
      "dtypes: datetime64[ns](1), int64(5), object(6)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_review.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get all the words and counts for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Run CountVectorizer for each row in ['lemmatized']\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "lemma_count = CountVectorizer()\n",
    "text1 = df_review['lemmatized'][0]\n",
    "# text1 = ['happy','birthday','new','york','city','happy']\n",
    "# text1 = ['happy birthday new york city happy']\n",
    "\n",
    "counts = lemma_count.fit_transform(text1) # a sparse matrix\n",
    "counts = counts.toarray()\n",
    "# counts.sum(axis=0) # same as toarray, but it's a matrix\n",
    "# print counts\n",
    "# print counts.shape\n",
    "vocab = lemma_count.get_feature_names() # a list\n",
    "# len(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 3, 2, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.reshape(40,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'and', 1),\n",
       " (u'around', 1),\n",
       " (u'ask', 1),\n",
       " (u'can', 1),\n",
       " (u'cut', 1),\n",
       " (u'dinner', 1),\n",
       " (u'do', 1),\n",
       " (u'fatty', 1),\n",
       " (u'for', 1),\n",
       " (u'french', 1),\n",
       " (u'fry', 1),\n",
       " (u'get', 1),\n",
       " (u'half', 1),\n",
       " (u'hand', 1),\n",
       " (u'hot', 1),\n",
       " (u'hour', 1),\n",
       " (u'how', 1),\n",
       " (u'just', 1),\n",
       " (u'lean', 1),\n",
       " (u'line', 1),\n",
       " (u'long', 1),\n",
       " (u'love', 3),\n",
       " (u'lunch', 1),\n",
       " (u'maybe', 1),\n",
       " (u'meat', 2),\n",
       " (u'not', 2),\n",
       " (u'or', 2),\n",
       " (u'pepper', 1),\n",
       " (u'pickle', 1),\n",
       " (u'place', 1),\n",
       " (u'prepare', 1),\n",
       " (u'pron', 7),\n",
       " (u'remember', 1),\n",
       " (u'say', 1),\n",
       " (u'something', 1),\n",
       " (u'sour', 1),\n",
       " (u'staff', 1),\n",
       " (u'the', 3),\n",
       " (u'too', 2),\n",
       " (u'want', 2)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vv = np.array(vocab)\n",
    "vv = vv.reshape(-1,)\n",
    "counts = counts.reshape(-1,)\n",
    "zip(vv, counts)\n",
    "# a = np.array([1,2,3])\n",
    "# a_temp = np.array([1,2,3]).reshape(3,1)\n",
    "# print a.shape\n",
    "# print a_temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_lemma(text):\n",
    "    lemma_count = CountVectorizer(stop_words = None, analyzer = 'word', token_pattern= r\"(?u)\\b\\w+\\b\")\n",
    "    counts = lemma_count.fit_transform(text)\n",
    "    vocab = lemma_count.get_feature_names()\n",
    "    vocab = np.array(vocab).reshape(-1,)\n",
    "    counts = counts.toarray().reshape(-1,)\n",
    "            \n",
    "    return zip(vocab, counts) \n",
    "\n",
    "\n",
    "# testing = df_review['lemmatized'][:5]\n",
    "# df_review['testing'] = None\n",
    "\n",
    "# test = CountVectorizer()\n",
    "# for i,text in enumerate(testing):\n",
    "#     df_review['testing'][i] = count_lemma(text)\n",
    "\n",
    "# df_review['testing'][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_lemma_test(text):\n",
    "    lemma_count = CountVectorizer(stop_words = None, analyzer = 'word', token_pattern= r\"[^\\d\\W]\")\n",
    "    counts = lemma_count.fit_transform(text)\n",
    "    vocab = lemma_count.get_feature_names()\n",
    "    vocab = np.array(vocab).reshape(-1,)\n",
    "    counts = counts.toarray().reshape(-1,)\n",
    "            \n",
    "    return zip(vocab, counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_review['count_vec'] = map(lambda x: count_lemma(x), df_review['lemmatized'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_review.to_pickle('yelp_review_cleaned_0710v3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>date</th>\n",
       "      <th>funny</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>useful</th>\n",
       "      <th>user_id</th>\n",
       "      <th>lemma_clean</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>count_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0W4lkclzZThpx3V65bVgig</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>v0i_UHJMo_hPBq9bxWvW4w</td>\n",
       "      <td>5</td>\n",
       "      <td>Love the staff, love the meat, love the place....</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[love, the, staff, love, the, meat, love, the,...</td>\n",
       "      <td>6</td>\n",
       "      <td>[love the staff love the meat love the place p...</td>\n",
       "      <td>[(a, 3), (and, 1), (around, 1), (ask, 1), (can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AEx2SYEUJmTxVVB18LlCwA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>vkVSCC7xljjrAI4UGfnKEQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Super simple place but amazing nonetheless. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[super, simple, place, but, amazing, nonethele...</td>\n",
       "      <td>3</td>\n",
       "      <td>[super simple place but amazing nonetheless PR...</td>\n",
       "      <td>[(30, 1), (a, 1), (amazing, 1), (and, 3), (aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VR6GpWIda3SfvPC-lg9H3w</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>n6QzIUObkYshz4dz2QRJTw</td>\n",
       "      <td>5</td>\n",
       "      <td>Small unassuming place that changes their menu...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[small, unassum, place, that, change, PRON, me...</td>\n",
       "      <td>8</td>\n",
       "      <td>[small unassum place that change PRON menu eve...</td>\n",
       "      <td>[(10, 1), (30, 1), (a, 4), (about, 1), (all, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CKC0-MOWMqoeWf6s-szl8g</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>MV3CcKScW05u5LVfF6ok0g</td>\n",
       "      <td>5</td>\n",
       "      <td>Lester's is located in a beautiful neighborhoo...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[lester, s, be, locate, in, a, beautiful, neig...</td>\n",
       "      <td>4</td>\n",
       "      <td>[lester s be locate in a beautiful neighborhoo...</td>\n",
       "      <td>[(12, 1), (1951, 1), (a, 1), (about, 1), (alon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACFtxLv8pGrrxMm6EgjreA</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-05-28</td>\n",
       "      <td>0</td>\n",
       "      <td>IXvOzsEMYtiJI0CARmj77Q</td>\n",
       "      <td>4</td>\n",
       "      <td>Love coming here. Yes the place always needs t...</td>\n",
       "      <td>0</td>\n",
       "      <td>bv2nCi5Qv5vroFiqKGopiw</td>\n",
       "      <td>[love, come, here, yes, the, place, always, ne...</td>\n",
       "      <td>6</td>\n",
       "      <td>[love come here yes the place always need the ...</td>\n",
       "      <td>[(1, 1), (2, 1), (a, 4), (add, 1), (always, 3)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  cool       date  funny               review_id  \\\n",
       "0  0W4lkclzZThpx3V65bVgig     0 2016-05-28      0  v0i_UHJMo_hPBq9bxWvW4w   \n",
       "1  AEx2SYEUJmTxVVB18LlCwA     0 2016-05-28      0  vkVSCC7xljjrAI4UGfnKEQ   \n",
       "2  VR6GpWIda3SfvPC-lg9H3w     0 2016-05-28      0  n6QzIUObkYshz4dz2QRJTw   \n",
       "3  CKC0-MOWMqoeWf6s-szl8g     0 2016-05-28      0  MV3CcKScW05u5LVfF6ok0g   \n",
       "4  ACFtxLv8pGrrxMm6EgjreA     0 2016-05-28      0  IXvOzsEMYtiJI0CARmj77Q   \n",
       "\n",
       "   stars                                               text  useful  \\\n",
       "0      5  Love the staff, love the meat, love the place....       0   \n",
       "1      5  Super simple place but amazing nonetheless. It...       0   \n",
       "2      5  Small unassuming place that changes their menu...       0   \n",
       "3      5  Lester's is located in a beautiful neighborhoo...       0   \n",
       "4      4  Love coming here. Yes the place always needs t...       0   \n",
       "\n",
       "                  user_id                                        lemma_clean  \\\n",
       "0  bv2nCi5Qv5vroFiqKGopiw  [love, the, staff, love, the, meat, love, the,...   \n",
       "1  bv2nCi5Qv5vroFiqKGopiw  [super, simple, place, but, amazing, nonethele...   \n",
       "2  bv2nCi5Qv5vroFiqKGopiw  [small, unassum, place, that, change, PRON, me...   \n",
       "3  bv2nCi5Qv5vroFiqKGopiw  [lester, s, be, locate, in, a, beautiful, neig...   \n",
       "4  bv2nCi5Qv5vroFiqKGopiw  [love, come, here, yes, the, place, always, ne...   \n",
       "\n",
       "   sent_count                                         lemmatized  \\\n",
       "0           6  [love the staff love the meat love the place p...   \n",
       "1           3  [super simple place but amazing nonetheless PR...   \n",
       "2           8  [small unassum place that change PRON menu eve...   \n",
       "3           4  [lester s be locate in a beautiful neighborhoo...   \n",
       "4           6  [love come here yes the place always need the ...   \n",
       "\n",
       "                                           count_vec  \n",
       "0  [(a, 3), (and, 1), (around, 1), (ask, 1), (can...  \n",
       "1  [(30, 1), (a, 1), (amazing, 1), (and, 3), (aro...  \n",
       "2  [(10, 1), (30, 1), (a, 4), (about, 1), (all, 1...  \n",
       "3  [(12, 1), (1951, 1), (a, 1), (about, 1), (alon...  \n",
       "4  [(1, 1), (2, 1), (a, 4), (add, 1), (always, 3)...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'a', 3),\n",
       " (u'all', 2),\n",
       " (u'and', 2),\n",
       " (u'appetizer', 1),\n",
       " (u'back', 1),\n",
       " (u'be', 2),\n",
       " (u'before', 1),\n",
       " (u'birthday', 2),\n",
       " (u'care', 1),\n",
       " (u'charlene', 1),\n",
       " (u'cocktail', 1),\n",
       " (u'couple', 1),\n",
       " (u'different', 1),\n",
       " (u'drink', 1),\n",
       " (u'fantastic', 1),\n",
       " (u'for', 2),\n",
       " (u'good', 1),\n",
       " (u'great', 1),\n",
       " (u'have', 2),\n",
       " (u'house', 1),\n",
       " (u'in', 1),\n",
       " (u'just', 1),\n",
       " (u'like', 1),\n",
       " (u'make', 1),\n",
       " (u'name', 1),\n",
       " (u'new', 1),\n",
       " (u'night', 1),\n",
       " (u'of', 2),\n",
       " (u'order', 1),\n",
       " (u'perfectly', 1),\n",
       " (u'porter', 1),\n",
       " (u'pron', 8),\n",
       " (u's', 1),\n",
       " (u'say', 1),\n",
       " (u'server', 1),\n",
       " (u'sisters', 1),\n",
       " (u'stop', 1),\n",
       " (u'take', 1),\n",
       " (u'the', 3),\n",
       " (u'this', 1),\n",
       " (u'to', 1),\n",
       " (u'try', 1),\n",
       " (u'update', 1),\n",
       " (u'venue', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_lemma(df_review[\"lemmatized\"][3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Star_5 = df_review[df_review['stars'] == 3][\"lemmatized\"]\n",
    "\n",
    "#df_review[[\"lemmatized\", \"stars\"]][df_review['stars'] == 5][\"lemmatized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [love the staff , love the meat , love the pla...\n",
       "1    [super simple place but amazing nonetheless . ...\n",
       "2    [small unassum place that change -PRON- menu e...\n",
       "3    [lester 's be locate in a beautiful neighborho...\n",
       "6    [cycle pub las vegas be a blast ! get a groupo...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Star_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15294599533\n"
     ]
    }
   ],
   "source": [
    "# lemmat_test_1 = [\",\".join(df_review[][\"lemmatized\"][:2].sum())]\n",
    "# count_lemma(lemmat_test_1)\n",
    "import time\n",
    "t0 = time.time()\n",
    "star5_dict = count_lemma([\",\".join(Star_5.sum())])\n",
    "t1 = time.time()\n",
    "print t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_five_stars = pd.DataFrame(star5_dict, columns = [\"word\", \"count\"])\\\n",
    ".sort_values(\"count\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>pron</td>\n",
       "      <td>153192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>be</td>\n",
       "      <td>93912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24723</th>\n",
       "      <td>the</td>\n",
       "      <td>84225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>and</td>\n",
       "      <td>47031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>a</td>\n",
       "      <td>43328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25024</th>\n",
       "      <td>to</td>\n",
       "      <td>35970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17030</th>\n",
       "      <td>not</td>\n",
       "      <td>24975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17280</th>\n",
       "      <td>of</td>\n",
       "      <td>24453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11659</th>\n",
       "      <td>have</td>\n",
       "      <td>23926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9814</th>\n",
       "      <td>for</td>\n",
       "      <td>19405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4031</th>\n",
       "      <td>but</td>\n",
       "      <td>17485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12609</th>\n",
       "      <td>in</td>\n",
       "      <td>16863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24717</th>\n",
       "      <td>that</td>\n",
       "      <td>14818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10917</th>\n",
       "      <td>good</td>\n",
       "      <td>12824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>do</td>\n",
       "      <td>12422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27399</th>\n",
       "      <td>with</td>\n",
       "      <td>12255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17410</th>\n",
       "      <td>on</td>\n",
       "      <td>11208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24800</th>\n",
       "      <td>this</td>\n",
       "      <td>10968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10639</th>\n",
       "      <td>get</td>\n",
       "      <td>8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9787</th>\n",
       "      <td>food</td>\n",
       "      <td>8520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22832</th>\n",
       "      <td>so</td>\n",
       "      <td>8459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18727</th>\n",
       "      <td>place</td>\n",
       "      <td>7917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2030</th>\n",
       "      <td>at</td>\n",
       "      <td>7715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10864</th>\n",
       "      <td>go</td>\n",
       "      <td>7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24750</th>\n",
       "      <td>there</td>\n",
       "      <td>7244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14490</th>\n",
       "      <td>like</td>\n",
       "      <td>7083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>as</td>\n",
       "      <td>6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27530</th>\n",
       "      <td>would</td>\n",
       "      <td>6985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12476</th>\n",
       "      <td>if</td>\n",
       "      <td>6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13525</th>\n",
       "      <td>just</td>\n",
       "      <td>5905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17518</th>\n",
       "      <td>order</td>\n",
       "      <td>5776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24942</th>\n",
       "      <td>time</td>\n",
       "      <td>5592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26535</th>\n",
       "      <td>very</td>\n",
       "      <td>5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5487</th>\n",
       "      <td>come</td>\n",
       "      <td>5440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17628</th>\n",
       "      <td>out</td>\n",
       "      <td>5430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11847</th>\n",
       "      <td>here</td>\n",
       "      <td>5076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>all</td>\n",
       "      <td>5067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17412</th>\n",
       "      <td>one</td>\n",
       "      <td>4940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22004</th>\n",
       "      <td>service</td>\n",
       "      <td>4803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17502</th>\n",
       "      <td>or</td>\n",
       "      <td>4694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20083</th>\n",
       "      <td>really</td>\n",
       "      <td>4412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27313</th>\n",
       "      <td>will</td>\n",
       "      <td>4307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11096</th>\n",
       "      <td>great</td>\n",
       "      <td>4298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27205</th>\n",
       "      <td>which</td>\n",
       "      <td>4209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27193</th>\n",
       "      <td>when</td>\n",
       "      <td>4175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>up</td>\n",
       "      <td>4050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>can</td>\n",
       "      <td>4027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22933</th>\n",
       "      <td>some</td>\n",
       "      <td>3954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10086</th>\n",
       "      <td>from</td>\n",
       "      <td>3810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25498</th>\n",
       "      <td>try</td>\n",
       "      <td>3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16242</th>\n",
       "      <td>more</td>\n",
       "      <td>3772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>about</td>\n",
       "      <td>3707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17604</th>\n",
       "      <td>other</td>\n",
       "      <td>3669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15071</th>\n",
       "      <td>make</td>\n",
       "      <td>3642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>an</td>\n",
       "      <td>3566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "      <td>back</td>\n",
       "      <td>3466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16844</th>\n",
       "      <td>nice</td>\n",
       "      <td>3425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27168</th>\n",
       "      <td>what</td>\n",
       "      <td>3369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21179</th>\n",
       "      <td>s</td>\n",
       "      <td>3340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2743</th>\n",
       "      <td>because</td>\n",
       "      <td>3285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21513</th>\n",
       "      <td>say</td>\n",
       "      <td>3211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17421</th>\n",
       "      <td>only</td>\n",
       "      <td>3179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24784</th>\n",
       "      <td>think</td>\n",
       "      <td>3172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>pretty</td>\n",
       "      <td>3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>also</td>\n",
       "      <td>3106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16933</th>\n",
       "      <td>no</td>\n",
       "      <td>3091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25129</th>\n",
       "      <td>too</td>\n",
       "      <td>3016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19332</th>\n",
       "      <td>price</td>\n",
       "      <td>2963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20597</th>\n",
       "      <td>restaurant</td>\n",
       "      <td>2912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24315</th>\n",
       "      <td>take</td>\n",
       "      <td>2881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10755</th>\n",
       "      <td>give</td>\n",
       "      <td>2817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14602</th>\n",
       "      <td>little</td>\n",
       "      <td>2725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14734</th>\n",
       "      <td>look</td>\n",
       "      <td>2720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26900</th>\n",
       "      <td>want</td>\n",
       "      <td>2663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24708</th>\n",
       "      <td>than</td>\n",
       "      <td>2650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4070</th>\n",
       "      <td>by</td>\n",
       "      <td>2559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>drink</td>\n",
       "      <td>2531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>much</td>\n",
       "      <td>2526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8041</th>\n",
       "      <td>eat</td>\n",
       "      <td>2481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>could</td>\n",
       "      <td>2408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>chicken</td>\n",
       "      <td>2361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21856</th>\n",
       "      <td>see</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27101</th>\n",
       "      <td>well</td>\n",
       "      <td>2273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24436</th>\n",
       "      <td>taste</td>\n",
       "      <td>2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>5</td>\n",
       "      <td>2263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26841</th>\n",
       "      <td>wait</td>\n",
       "      <td>2258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15656</th>\n",
       "      <td>menu</td>\n",
       "      <td>2221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24260</th>\n",
       "      <td>table</td>\n",
       "      <td>2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>after</td>\n",
       "      <td>2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23466</th>\n",
       "      <td>star</td>\n",
       "      <td>2185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141</th>\n",
       "      <td>bit</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24776</th>\n",
       "      <td>thing</td>\n",
       "      <td>2106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18309</th>\n",
       "      <td>people</td>\n",
       "      <td>2084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10120</th>\n",
       "      <td>fry</td>\n",
       "      <td>2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8786</th>\n",
       "      <td>even</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9467</th>\n",
       "      <td>find</td>\n",
       "      <td>2057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21862</th>\n",
       "      <td>seem</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>bad</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14772</th>\n",
       "      <td>lot</td>\n",
       "      <td>1958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word   count\n",
       "19500        pron  153192\n",
       "2688           be   93912\n",
       "24723         the   84225\n",
       "1476          and   47031\n",
       "643             a   43328\n",
       "25024          to   35970\n",
       "17030         not   24975\n",
       "17280          of   24453\n",
       "11659        have   23926\n",
       "9814          for   19405\n",
       "4031          but   17485\n",
       "12609          in   16863\n",
       "24717        that   14818\n",
       "10917        good   12824\n",
       "7532           do   12422\n",
       "27399        with   12255\n",
       "17410          on   11208\n",
       "24800        this   10968\n",
       "10639         get    8720\n",
       "9787         food    8520\n",
       "22832          so    8459\n",
       "18727       place    7917\n",
       "2030           at    7715\n",
       "10864          go    7664\n",
       "24750       there    7244\n",
       "14490        like    7083\n",
       "1926           as    6999\n",
       "27530       would    6985\n",
       "12476          if    6246\n",
       "13525        just    5905\n",
       "17518       order    5776\n",
       "24942        time    5592\n",
       "26535        very    5472\n",
       "5487         come    5440\n",
       "17628         out    5430\n",
       "11847        here    5076\n",
       "1237          all    5067\n",
       "17412         one    4940\n",
       "22004     service    4803\n",
       "17502          or    4694\n",
       "20083      really    4412\n",
       "27313        will    4307\n",
       "11096       great    4298\n",
       "27205       which    4209\n",
       "27193        when    4175\n",
       "26152          up    4050\n",
       "4234          can    4027\n",
       "22933        some    3954\n",
       "10086        from    3810\n",
       "25498         try    3798\n",
       "16242        more    3772\n",
       "695         about    3707\n",
       "17604       other    3669\n",
       "15071        make    3642\n",
       "1457           an    3566\n",
       "2373         back    3466\n",
       "16844        nice    3425\n",
       "27168        what    3369\n",
       "21179           s    3340\n",
       "2743      because    3285\n",
       "21513         say    3211\n",
       "17421        only    3179\n",
       "24784       think    3172\n",
       "19319      pretty    3112\n",
       "1322         also    3106\n",
       "16933          no    3091\n",
       "25129         too    3016\n",
       "19332       price    2963\n",
       "20597  restaurant    2912\n",
       "24315        take    2881\n",
       "10755        give    2817\n",
       "14602      little    2725\n",
       "14734        look    2720\n",
       "26900        want    2663\n",
       "24708        than    2650\n",
       "4070           by    2559\n",
       "7768        drink    2531\n",
       "16377        much    2526\n",
       "8041          eat    2481\n",
       "330             3    2454\n",
       "6073        could    2408\n",
       "4885      chicken    2361\n",
       "21856         see    2292\n",
       "27101        well    2273\n",
       "24436       taste    2270\n",
       "460             5    2263\n",
       "26841        wait    2258\n",
       "15656        menu    2221\n",
       "24260       table    2206\n",
       "1025        after    2202\n",
       "23466        star    2185\n",
       "3141          bit    2110\n",
       "24776       thing    2106\n",
       "18309      people    2084\n",
       "10120         fry    2080\n",
       "8786         even    2073\n",
       "9467         find    2057\n",
       "21862        seem    1992\n",
       "2390          bad    1973\n",
       "14772         lot    1958"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_five_stars.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Find the most frequent N words in 1-star and 5-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = [('happy',1),('cookie',2),('always',1),('about',4),('cannot',1)]\n",
    "B = [('pasta',2),('lunch',1),('about',1),('time',4),('okay',2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('about', 1),\n",
       " ('okay', 2),\n",
       " ('always', 1),\n",
       " ('lunch', 1),\n",
       " ('cannot', 1),\n",
       " ('cookie', 2),\n",
       " ('time', 4),\n",
       " ('pasta', 2),\n",
       " ('happy', 1)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from collections import defaultdict\n",
    "# d = defaultdict(list)\n",
    "# for a, b in A+B:\n",
    "#     d[a].append(b)\n",
    "\n",
    "d1 = dict(A)\n",
    "d1.update(dict(B))\n",
    "list(d1.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'a', 3),\n",
       " (u'and', 1),\n",
       " (u'around', 1),\n",
       " (u'ask', 1),\n",
       " (u'can', 1),\n",
       " (u'cut', 1),\n",
       " (u'dinner', 1),\n",
       " (u'do', 1),\n",
       " (u'fatty', 1),\n",
       " (u'for', 1),\n",
       " (u'french', 1),\n",
       " (u'fry', 1),\n",
       " (u'get', 1),\n",
       " (u'half', 1),\n",
       " (u'hand', 1),\n",
       " (u'hot', 1),\n",
       " (u'hour', 1),\n",
       " (u'how', 1),\n",
       " (u'just', 1),\n",
       " (u'lean', 1),\n",
       " (u'line', 1),\n",
       " (u'long', 1),\n",
       " (u'love', 3),\n",
       " (u'lunch', 1),\n",
       " (u'maybe', 1),\n",
       " (u'meat', 2),\n",
       " (u'not', 2),\n",
       " (u'or', 2),\n",
       " (u'pepper', 1),\n",
       " (u'pickle', 1),\n",
       " (u'place', 1),\n",
       " (u'prepare', 1),\n",
       " (u'pron', 7),\n",
       " (u'remember', 1),\n",
       " (u'say', 1),\n",
       " (u'something', 1),\n",
       " (u'sour', 1),\n",
       " (u'staff', 1),\n",
       " (u'the', 3),\n",
       " (u'too', 2),\n",
       " (u'want', 2)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review['word_frequency'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_smallset = df_review.head(1000)\n",
    "df_smallset.to_pickle('yelp_review_cleaned_small.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use word-to-vec to get a feature matrix and use it to \n",
    "## run linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyCP",
   "language": "python",
   "name": "cp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
